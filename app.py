import streamlit as st
import os
import json
from typing import List, Dict, Optional
from datetime import datetime

# v3.0.0: å¯¼å…¥ CrewAI å¤š Agent ç³»ç»Ÿ
try:
    from agent_crew import CharacterAgentCrew
    CREWAI_AVAILABLE = True
except ImportError:
    CREWAI_AVAILABLE = False
    st.warning("âš ï¸ CrewAI æœªå®‰è£…ï¼Œä½¿ç”¨é™çº§æ¨¡å¼")

# åˆå§‹åŒ– session state
def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ - v2.2.0 å¤š Agent æ¶æ„"""
    if 'chat_mode' not in st.session_state:
        st.session_state.chat_mode = 'group'  # 'group' æˆ– 'private'

    if 'scene' not in st.session_state:
        st.session_state.scene = ''

    if 'characters' not in st.session_state:
        st.session_state.characters = []

    if 'num_characters' not in st.session_state:
        st.session_state.num_characters = 3  # é»˜è®¤3ä¸ªè§’è‰²

    # v2.2.0 æ–°æ¶æ„ï¼šçœŸæ­£çš„å¤š Agent è®°å¿†ç³»ç»Ÿ
    if 'shared_events' not in st.session_state:
        # å…±äº«äº‹ä»¶æµï¼ˆç¾¤èŠæ¶ˆæ¯ï¼‰ï¼Œç”¨äºæ˜¾ç¤ºç¾¤èŠç•Œé¢
        st.session_state.shared_events = []

    if 'character_memories' not in st.session_state:
        # æ¯ä¸ªè§’è‰²çš„ç‹¬ç«‹è®°å¿†ï¼ˆåŒ…å«ç¾¤èŠ+è‡ªå·±çš„ç§èŠï¼‰
        st.session_state.character_memories = {}

    if 'selected_character' not in st.session_state:
        st.session_state.selected_character = None

    if 'conversation_started' not in st.session_state:
        st.session_state.conversation_started = False

    if 'api_key' not in st.session_state:
        st.session_state.api_key = ''

    # v3.0.0: CrewAI Agent ç®¡ç†å™¨
    if 'crew_manager' not in st.session_state:
        st.session_state.crew_manager = None

    # v3.0.0: ä½¿ç”¨ CrewAI æ¨¡å¼
    if 'use_crewai' not in st.session_state:
        st.session_state.use_crewai = True  # é»˜è®¤å¯ç”¨


# ============= v3.0.0 CrewAI è¾…åŠ©å‡½æ•° =============

def _fallback_sequential_generation(user_input, use_real_api, api_key, status_placeholder):
    """
    é™çº§æ–¹æ¡ˆï¼šä¼ ç»Ÿé¡ºåºå‘è¨€æ¨¡å¼
    å½“ CrewAI ä¸å¯ç”¨æˆ–å¤±è´¥æ—¶ä½¿ç”¨
    """
    for idx, char in enumerate(st.session_state.characters, 1):
        status_placeholder.info(f"ğŸ¤” {char['name']} æ­£åœ¨å›å¤... ({idx}/{len(st.session_state.characters)})")

        # è·å–è§’è‰²çš„å®Œæ•´è®°å¿†
        char_memory = get_character_memory(char['name'])

        # ç”Ÿæˆå›å¤
        if use_real_api and api_key:
            content = generate_single_reply_with_gemini(
                st.session_state.scene,
                char,
                st.session_state.characters,
                char_memory,
                is_initial=False,
                api_key=api_key
            )
        else:
            content = mock_generate_single_reply(
                st.session_state.scene,
                char,
                char_memory,
                is_initial=False
            )

        # æ·»åŠ åˆ°è®°å¿†ç³»ç»Ÿ
        add_group_message(char['name'], content, 'character')


# ============= v2.2.0 å¤š Agent è®°å¿†ç®¡ç†ç³»ç»Ÿ =============

def init_character_memories():
    """åˆå§‹åŒ–æ‰€æœ‰è§’è‰²çš„è®°å¿†"""
    st.session_state.character_memories = {
        char['name']: [] for char in st.session_state.characters
    }


def add_group_message(speaker: str, content: str, msg_type: str = 'character'):
    """
    æ·»åŠ ç¾¤èŠæ¶ˆæ¯ï¼ˆæ‰€æœ‰è§’è‰²éƒ½èƒ½çœ‹åˆ°ï¼‰

    Args:
        speaker: å‘è¨€è€…åç§°
        content: æ¶ˆæ¯å†…å®¹
        msg_type: æ¶ˆæ¯ç±»å‹ ('user' æˆ– 'character')
    """
    message = {
        'timestamp': datetime.now().isoformat(),
        'speaker': speaker,
        'content': content,
        'type': 'group',
        'msg_type': msg_type,
        'visible_to': 'all'
    }

    # æ·»åŠ åˆ°å…±äº«äº‹ä»¶æµï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    st.session_state.shared_events.append(message)

    # æ·»åŠ åˆ°æ‰€æœ‰è§’è‰²çš„è®°å¿†
    for char_name in st.session_state.character_memories:
        st.session_state.character_memories[char_name].append(message.copy())


def add_private_message(character_name: str, speaker: str, content: str, msg_type: str = 'character'):
    """
    æ·»åŠ ç§èŠæ¶ˆæ¯ï¼ˆåªæœ‰æŒ‡å®šè§’è‰²èƒ½çœ‹åˆ°ï¼‰

    Args:
        character_name: è§’è‰²åç§°
        speaker: å‘è¨€è€…åç§°
        content: æ¶ˆæ¯å†…å®¹
        msg_type: æ¶ˆæ¯ç±»å‹ ('user' æˆ– 'character')
    """
    message = {
        'timestamp': datetime.now().isoformat(),
        'speaker': speaker,
        'content': content,
        'type': 'private',
        'msg_type': msg_type,
        'visible_to': [character_name]
    }

    # åªæ·»åŠ åˆ°æŒ‡å®šè§’è‰²çš„è®°å¿†
    if character_name in st.session_state.character_memories:
        st.session_state.character_memories[character_name].append(message)


def get_character_memory(character_name: str, limit: int = 20) -> List[Dict]:
    """
    è·å–è§’è‰²çš„è®°å¿†ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰

    Args:
        character_name: è§’è‰²åç§°
        limit: è¿”å›æœ€è¿‘ N æ¡è®°å¿†

    Returns:
        è§’è‰²çš„è®°å¿†åˆ—è¡¨
    """
    if character_name not in st.session_state.character_memories:
        return []

    memories = st.session_state.character_memories[character_name]
    # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆå·²ç»æ˜¯æŒ‰é¡ºåºæ·»åŠ çš„ï¼Œä½†ä¿é™©èµ·è§ï¼‰
    sorted_memories = sorted(memories, key=lambda x: x['timestamp'])
    return sorted_memories[-limit:] if limit > 0 else sorted_memories


def get_private_messages(character_name: str) -> List[Dict]:
    """
    è·å–è§’è‰²çš„æ‰€æœ‰ç§èŠæ¶ˆæ¯

    Args:
        character_name: è§’è‰²åç§°

    Returns:
        ç§èŠæ¶ˆæ¯åˆ—è¡¨
    """
    if character_name not in st.session_state.character_memories:
        return []

    return [
        msg for msg in st.session_state.character_memories[character_name]
        if msg['type'] == 'private'
    ]


# ============= ç»“æŸè®°å¿†ç®¡ç†ç³»ç»Ÿ =============


# é¢„è®¾ç®¡ç†
def load_preset_from_json(json_str: str) -> bool:
    """
    ä» JSON å­—ç¬¦ä¸²åŠ è½½é¢„è®¾

    Args:
        json_str: JSON æ ¼å¼çš„é¢„è®¾æ•°æ®

    Returns:
        åŠ è½½æ˜¯å¦æˆåŠŸ
    """
    try:
        data = json.loads(json_str)

        # éªŒè¯å¿…è¦å­—æ®µ
        if 'scene' not in data or 'characters' not in data:
            st.error("é¢„è®¾æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘ scene æˆ– characters å­—æ®µ")
            return False

        # åŠ è½½é¢„è®¾
        st.session_state.scene = data.get('scene', '')
        st.session_state.characters = data.get('characters', [])
        st.session_state.num_characters = len(st.session_state.characters)

        # å¯é€‰ï¼šåŠ è½½ API Key
        if 'api_key' in data and data['api_key']:
            st.session_state.api_key = data['api_key']

        st.success(f"âœ… é¢„è®¾ '{data.get('preset_name', 'æœªå‘½å')}' åŠ è½½æˆåŠŸï¼")
        return True
    except Exception as e:
        st.error(f"é¢„è®¾åŠ è½½å¤±è´¥: {str(e)}")
        return False


# ä¿å­˜å¯¹è¯å†å²åˆ° JSON æ–‡ä»¶
def save_conversation_to_json() -> str:
    """
    ä¿å­˜å½“å‰å¯¹è¯çŠ¶æ€åˆ° JSON æ–‡ä»¶ - v2.2.0 å¤š Agent æ¶æ„

    Returns:
        JSON å­—ç¬¦ä¸²ï¼Œå¯ç”¨äºä¸‹è½½
    """
    data = {
        'version': '2.2.0',
        'saved_at': datetime.now().isoformat(),
        'scene': st.session_state.scene,
        'characters': st.session_state.characters,
        'num_characters': st.session_state.num_characters,
        'shared_events': st.session_state.shared_events,
        'character_memories': st.session_state.character_memories,
        'conversation_started': st.session_state.conversation_started
    }
    return json.dumps(data, ensure_ascii=False, indent=2)


# ä» JSON åŠ è½½å¯¹è¯å†å²
def load_conversation_from_json(json_str: str) -> bool:
    """
    ä» JSON å­—ç¬¦ä¸²åŠ è½½å¯¹è¯å†å² - æ”¯æŒ v2.1.x åˆ° v2.2.0 çš„è¿ç§»

    Args:
        json_str: JSON æ ¼å¼çš„å¯¹è¯æ•°æ®

    Returns:
        åŠ è½½æ˜¯å¦æˆåŠŸ
    """
    try:
        data = json.loads(json_str)
        version = data.get('version', '1.0.0')

        st.info(f"åŠ è½½çš„å¯¹è¯ç‰ˆæœ¬: {version}")

        # æ¢å¤åŸºæœ¬çŠ¶æ€
        st.session_state.scene = data.get('scene', '')
        st.session_state.characters = data.get('characters', [])
        st.session_state.num_characters = data.get('num_characters', len(data.get('characters', [])))
        st.session_state.conversation_started = data.get('conversation_started', False)

        # ç‰ˆæœ¬å…¼å®¹å¤„ç†
        if version.startswith('2.2'):
            # v2.2.0 æ ¼å¼ï¼šç›´æ¥åŠ è½½æ–°æ¶æ„
            st.session_state.shared_events = data.get('shared_events', [])
            st.session_state.character_memories = data.get('character_memories', {})
        else:
            # v2.1.x æˆ–æ›´æ—©ç‰ˆæœ¬ï¼šè½¬æ¢åˆ°æ–°æ¶æ„
            st.warning("æ£€æµ‹åˆ°æ—§ç‰ˆæœ¬æ ¼å¼ï¼Œæ­£åœ¨è½¬æ¢åˆ° v2.2.0 æ¶æ„...")

            # åˆå§‹åŒ–æ–°ç»“æ„
            st.session_state.shared_events = []
            st.session_state.character_memories = {
                char['name']: [] for char in st.session_state.characters
            }

            # è¿ç§»ç¾¤èŠå†å²
            old_group_history = data.get('group_chat_history', [])
            for msg in old_group_history:
                speaker = msg.get('speaker', 'æœªçŸ¥')
                content = msg.get('content', '')
                msg_type = msg.get('type', 'character')
                add_group_message(speaker, content, msg_type)

            # è¿ç§»ç§èŠå†å²
            old_private_history = data.get('private_chat_history', {})
            for char_name, messages in old_private_history.items():
                for msg in messages:
                    speaker = msg.get('speaker', 'æœªçŸ¥')
                    content = msg.get('content', '')
                    msg_type = msg.get('type', 'character')
                    add_private_message(char_name, speaker, content, msg_type)

            st.success("âœ… å·²æˆåŠŸè½¬æ¢åˆ° v2.2.0 å¤š Agent æ¶æ„ï¼")

        return True
    except Exception as e:
        st.error(f"åŠ è½½å¤±è´¥: {str(e)}")
        return False


# é¡ºåºç”Ÿæˆå•ä¸ªè§’è‰²çš„å‘è¨€ï¼ˆMockç‰ˆæœ¬ï¼‰- v2.2.0 åŸºäºå®Œæ•´è®°å¿†
def mock_generate_single_reply(scene: str, character: Dict[str, str],
                                character_memory: List[Dict[str, str]], is_initial: bool = False) -> str:
    """
    Mock function: ç”Ÿæˆå•ä¸ªè§’è‰²çš„å‘è¨€ï¼ˆåŸºäºè§’è‰²å®Œæ•´è®°å¿†ï¼‰

    Args:
        scene: åœºæ™¯æè¿°
        character: è§’è‰²ä¿¡æ¯
        character_memory: è§’è‰²çš„å®Œæ•´è®°å¿†ï¼ˆåŒ…å«ç¾¤èŠ+ç§èŠï¼‰
        is_initial: æ˜¯å¦æ˜¯åˆå§‹å¯¹è¯

    Returns:
        è§’è‰²çš„å‘è¨€å†…å®¹
    """
    if is_initial and len(character_memory) == 0:
        return f"å¤§å®¶å¥½ï¼{scene}çœŸæ˜¯ä¸ªæœ‰è¶£çš„åœ°æ–¹ã€‚æˆ‘æ˜¯{character['name']}ã€‚"
    elif is_initial:
        # åˆå§‹å¯¹è¯ï¼Œå›åº”å‰é¢çš„è§’è‰²
        return f"({character['personality']})æˆ‘ä¹Ÿå¾ˆæœŸå¾…ï¼è®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢å§ã€‚"
    else:
        # ç»­å†™å¯¹è¯ï¼ŒåŸºäºå®Œæ•´è®°å¿†
        # æ£€æŸ¥æ˜¯å¦æœ‰ç§èŠè®°å¿†
        private_msgs = [m for m in character_memory if m['type'] == 'private']
        has_secret = len(private_msgs) > 0

        last_msg = character_memory[-1] if character_memory else None

        if has_secret and len(character_memory) % 5 == 0:
            # å¶å°”æš—ç¤ºç§èŠå†…å®¹
            return f"({character['personality']})åŸºäºæˆ‘äº†è§£çš„ä¸€äº›ä¿¡æ¯ï¼Œæˆ‘è§‰å¾—..."
        elif last_msg and last_msg.get('msg_type') == 'user':
            return f"({character['personality']})å¬åˆ°ä½ è¯´'{last_msg['content']}'ï¼Œæˆ‘è§‰å¾—å¾ˆæœ‰æ„æ€ï¼"
        else:
            return f"({character['personality']})å¯¹äºåˆšæ‰çš„è®¨è®ºï¼Œæˆ‘æƒ³è¡¥å……ä¸€ç‚¹..."


# æ¨¡æ‹Ÿç”Ÿæˆåˆå§‹ç¾¤èŠå¯¹è¯ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
def mock_generate_initial_conversation(scene: str, characters: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """
    Mock function: ç”Ÿæˆåˆå§‹ç¾¤èŠå¯¹è¯ï¼ˆæ—§ç‰ˆæœ¬ï¼Œå·²è¢«é¡ºåºå‘è¨€å–ä»£ï¼‰
    ä»…ç”¨äºå‘åå…¼å®¹ï¼Œå®é™…ä½¿ç”¨é¡ºåºå‘è¨€æœºåˆ¶
    """
    messages = []
    for char in characters:
        content = mock_generate_single_reply(scene, char, messages, is_initial=True)
        messages.append({
            'speaker': char['name'],
            'content': content,
            'type': 'character'
        })
    return messages


# æ¨¡æ‹Ÿç”Ÿæˆç¾¤èŠç»­å†™å›å¤ï¼ˆå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
def mock_generate_group_reply(scene: str, characters: List[Dict[str, str]],
                               chat_history: List[Dict[str, str]], user_message: str) -> List[Dict[str, str]]:
    """
    Mock function: æ ¹æ®ç”¨æˆ·å‘è¨€ç”Ÿæˆè§’è‰²ä»¬çš„å›å¤ï¼ˆæ—§ç‰ˆæœ¬ï¼Œå·²è¢«é¡ºåºå‘è¨€å–ä»£ï¼‰
    ä»…ç”¨äºå‘åå…¼å®¹
    """
    replies = []
    for char in characters:
        content = mock_generate_single_reply(scene, char, chat_history, is_initial=False)
        replies.append({
            'speaker': char['name'],
            'content': content,
            'type': 'character'
        })
    return replies


# æ¨¡æ‹Ÿç”Ÿæˆç§èŠå›å¤
def mock_generate_private_reply(scene: str, character: Dict[str, str],
                                chat_history: List[Dict[str, str]], user_message: str) -> str:
    """
    Mock function: ç”Ÿæˆç§èŠå›å¤
    """
    return f"({character['personality']})å…³äº'{user_message}'è¿™ä¸ªé—®é¢˜ï¼Œè®©æˆ‘ç§ä¸‹è·Ÿä½ è¯´..."


# ä½¿ç”¨ Gemini API ç”Ÿæˆå•ä¸ªè§’è‰²çš„å‘è¨€ - v2.2.0 åŸºäºå®Œæ•´è®°å¿†
def generate_single_reply_with_gemini(scene: str, character: Dict[str, str],
                                      characters: List[Dict[str, str]],
                                      character_memory: List[Dict[str, str]],
                                      is_initial: bool, api_key: str) -> str:
    """
    ä½¿ç”¨ Gemini API ç”Ÿæˆå•ä¸ªè§’è‰²çš„å‘è¨€ï¼ˆåŸºäºè§’è‰²å®Œæ•´è®°å¿†ï¼‰

    Args:
        scene: åœºæ™¯æè¿°
        character: å½“å‰å‘è¨€çš„è§’è‰²
        characters: æ‰€æœ‰è§’è‰²åˆ—è¡¨
        character_memory: è§’è‰²çš„å®Œæ•´è®°å¿†ï¼ˆåŒ…å«ç¾¤èŠ+ç§èŠï¼‰
        is_initial: æ˜¯å¦æ˜¯åˆå§‹å¯¹è¯
        api_key: APIå¯†é’¥

    Returns:
        è§’è‰²çš„å‘è¨€å†…å®¹
    """
    try:
        import google.genai as genai

        client = genai.Client(api_key=api_key)

        # æ„å»ºè§’è‰²è®°å¿†ï¼ˆæœ€è¿‘20æ¡ï¼‰
        recent_memory = character_memory[-20:] if len(character_memory) > 20 else character_memory

        # åˆ†ç¦»ç¾¤èŠå’Œç§èŠè®°å¿†
        group_msgs = []
        private_msgs = []
        for msg in recent_memory:
            msg_line = f"{msg['speaker']}ï¼š{msg['content']}"
            if msg['type'] == 'group':
                group_msgs.append(msg_line)
            else:
                private_msgs.append(msg_line)

        # æ„å»ºæ˜¾ç¤ºæ–‡æœ¬
        group_text = "\n".join(group_msgs) if group_msgs else "ï¼ˆæš‚æ— ç¾¤èŠè®°å½•ï¼‰"
        private_text = "\n".join(private_msgs) if private_msgs else "ï¼ˆæš‚æ— ç§èŠè®°å½•ï¼‰"

        # æ„å»ºè§’è‰²åˆ—è¡¨
        characters_text = "\n".join([f"- {c['name']}: {c['personality']}" for c in characters])

        if is_initial:
            prompt = f"""
ä½ æ­£åœ¨æ‰®æ¼”è§’è‰²ï¼š{character['name']}ï¼ˆæ€§æ ¼ï¼š{character['personality']}ï¼‰
åœºæ™¯ï¼š{scene}

æ‰€æœ‰è§’è‰²ï¼š
{characters_text}

ç¾¤èŠè®°å½•ï¼š
{group_text}

è¯·ä»¥{character['name']}çš„èº«ä»½å’Œæ€§æ ¼ï¼Œåœ¨è¿™ä¸ªåœºæ™¯ä¸‹è¯´ä¸€å¥è¯ã€‚

ã€é‡è¦æç¤ºã€‘
- ä»”ç»†é˜…è¯»ä¸Šé¢çš„ç¾¤èŠè®°å½•ï¼Œç†è§£æ•´ä½“å¯¹è¯çš„æ°›å›´å’Œæ–¹å‘
- å¦‚æœä½ æ˜¯ç¬¬ä¸€ä¸ªå‘è¨€ï¼Œå¯ä»¥æ‰“æ‹›å‘¼å¹¶å¯¹åœºæ™¯åšå‡ºååº”
- å¦‚æœå‰é¢å·²æœ‰äººå‘è¨€ï¼Œä½ å¯ä»¥ï¼š
  * å›åº”ä»»ä½•ä¸€ä¸ªè§’è‰²è¯´çš„è¯ï¼ˆä¸ä»…ä»…æ˜¯æœ€åä¸€ä¸ªäººï¼‰
  * å¯¹æ•´ä½“å¯¹è¯åšå‡ºè¯„è®ºæˆ–è¡¥å……
  * æå‡ºæ–°çš„è¯é¢˜æˆ–è§‚ç‚¹
  * æ ¹æ®æ•´ä½“å¯¹è¯æ°›å›´è‡ªç„¶åœ°è¡¨è¾¾
- ä½ çš„å‘è¨€è¦ç¬¦åˆä½ çš„æ€§æ ¼ç‰¹ç‚¹
- è¦è®©å¯¹è¯è‡ªç„¶æµç•…ï¼Œä¸è¦ç”Ÿç¡¬
- åªè¾“å‡ºä½ è¦è¯´çš„ä¸€å¥è¯ï¼Œä¸è¦åŠ è§’è‰²åï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜

ä½ çš„å‘è¨€ï¼š
"""
        else:
            prompt = f"""
ä½ æ­£åœ¨æ‰®æ¼”è§’è‰²ï¼š{character['name']}ï¼ˆæ€§æ ¼ï¼š{character['personality']}ï¼‰
åœºæ™¯ï¼š{scene}

æ‰€æœ‰è§’è‰²ï¼š
{characters_text}

ã€ä½ çš„è®°å¿†ç³»ç»Ÿã€‘
ä½ æ‹¥æœ‰ä¸¤ç§è®°å¿†ï¼š

1. ç¾¤èŠè®°å½•ï¼ˆæ‰€æœ‰äººéƒ½èƒ½çœ‹åˆ°çš„å…¬å¼€å¯¹è¯ï¼‰ï¼š
{group_text}

2. ç§èŠè®°å½•ï¼ˆåªæœ‰ä½ çŸ¥é“çš„ç§å¯†ä¿¡æ¯ï¼‰ï¼š
{private_text}

è¯·ä»¥{character['name']}çš„èº«ä»½å’Œæ€§æ ¼ï¼Œåœ¨ç¾¤èŠä¸­å‘è¨€ã€‚

ã€é‡è¦æç¤ºã€‘
- ä»”ç»†é˜…è¯»ä½ çš„å®Œæ•´è®°å¿†ï¼ˆç¾¤èŠ+ç§èŠï¼‰ï¼Œç»Ÿæ½å…¨å±€ï¼Œç†è§£æ•´ä½“å¯¹è¯çš„èµ°å‘
- ä½ å¯ä»¥è‡ªç”±é€‰æ‹©å›åº”çš„å¯¹è±¡å’Œæ–¹å¼ï¼š
  * å›åº”ç”¨æˆ·çš„å‘è¨€
  * å›åº”ä»»ä½•ä¸€ä¸ªè§’è‰²è¯´çš„è¯
  * å¯¹ä¹‹å‰æåˆ°çš„è¯é¢˜è¿›è¡Œè¡¥å……æˆ–å»¶ä¼¸
  * ç»¼åˆå¤šä¸ªäººçš„è§‚ç‚¹ç»™å‡ºä½ çš„çœ‹æ³•
  * æå‡ºä¸å¯¹è¯ç›¸å…³çš„æ–°æƒ³æ³•
- **å…³é”®**ï¼šä½ å¯ä»¥åˆ©ç”¨ç§èŠä¸­è·å¾—çš„ä¿¡æ¯ï¼Œä½†è¦æ³¨æ„ï¼š
  * ä¸è¦ç›´æ¥æ³„éœ²ç§èŠå†…å®¹ï¼ˆå…¶ä»–äººä¸çŸ¥é“ï¼‰
  * å¯ä»¥å·§å¦™åœ°æš—ç¤ºæˆ–åˆ©ç”¨è¿™äº›ä¿¡æ¯
  * è®©ä½ çš„å‘è¨€æ›´æœ‰æ·±åº¦å’Œç­–ç•¥æ€§
- ä½ çš„å‘è¨€è¦åŸºäºå¯¹æ•´ä¸ªè®°å¿†çš„ç†è§£ï¼Œè€Œä¸æ˜¯åªçœ‹æœ€åä¸€æ¡æ¶ˆæ¯
- è¦è®©å¯¹è¯è¿è´¯ã€è‡ªç„¶ã€æœ‰æ·±åº¦
- å……åˆ†å±•ç°ä½ çš„æ€§æ ¼ç‰¹ç‚¹
- åªè¾“å‡ºä½ è¦è¯´çš„ä¸€å¥è¯ï¼Œä¸è¦åŠ è§’è‰²åï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜

ä½ çš„å‘è¨€ï¼š
"""

        response = client.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt
        )

        return response.text.strip()

    except Exception as e:
        st.warning(f"API è°ƒç”¨å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨ Mock æ•°æ®")
        return mock_generate_single_reply(scene, character, character_memory, is_initial)


# çœŸå®çš„ Gemini API è°ƒç”¨å‡½æ•°ï¼ˆæ—§ç‰ˆæœ¬ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
def generate_initial_conversation_with_gemini(scene: str, characters: List[Dict[str, str]], api_key: str) -> List[Dict[str, str]]:
    """
    ä½¿ç”¨ Gemini API ç”Ÿæˆåˆå§‹å¯¹è¯
    """
    try:
        import google.genai as genai

        client = genai.Client(api_key=api_key)

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªå‰§æœ¬åˆ›ä½œåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯åˆ›ä½œä¸€æ®µå¯¹è¯ï¼š

åœºæ™¯ï¼š{scene}

è§’è‰²ï¼š
1. {characters[0]['name']} - æ€§æ ¼ï¼š{characters[0]['personality']}
2. {characters[1]['name']} - æ€§æ ¼ï¼š{characters[1]['personality']}
3. {characters[2]['name']} - æ€§æ ¼ï¼š{characters[2]['personality']}

è¦æ±‚ï¼š
- è®©è¿™3ä¸ªè§’è‰²è¿›è¡Œ2è½®å¯¹è¯ï¼ˆæ¯è½®æ¯ä¸ªè§’è‰²è¯´ä¸€å¥è¯ï¼‰
- å¯¹è¯è¦ç¬¦åˆå„è‡ªçš„æ€§æ ¼ç‰¹ç‚¹
- å¯¹è¯è¦ä¸åœºæ™¯ç›¸å…³
- æ ¼å¼ï¼šè§’è‰²åï¼šå¯¹è¯å†…å®¹ï¼ˆæ¯è¡Œä¸€å¥ï¼‰

è¯·ç›´æ¥è¾“å‡ºå¯¹è¯å†…å®¹ï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜ã€‚
"""

        response = client.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt
        )

        # è§£æå“åº”ä¸ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        for line in response.text.strip().split('\n'):
            if 'ï¼š' in line or ':' in line:
                sep = 'ï¼š' if 'ï¼š' in line else ':'
                speaker, content = line.split(sep, 1)
                messages.append({
                    'speaker': speaker.strip(),
                    'content': content.strip(),
                    'type': 'character'
                })

        return messages if messages else mock_generate_initial_conversation(scene, characters)

    except Exception as e:
        st.warning(f"API è°ƒç”¨å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨ Mock æ•°æ®")
        return mock_generate_initial_conversation(scene, characters)


def generate_group_reply_with_gemini(scene: str, characters: List[Dict[str, str]],
                                     chat_history: List[Dict[str, str]], user_message: str, api_key: str) -> List[Dict[str, str]]:
    """ä½¿ç”¨ Gemini API ç”Ÿæˆç¾¤èŠå›å¤"""
    try:
        import google.genai as genai

        client = genai.Client(api_key=api_key)

        # æ„å»ºå¯¹è¯å†å²
        history_text = "\n".join([f"{msg['speaker']}ï¼š{msg['content']}" for msg in chat_history[-10:]])  # åªå–æœ€è¿‘10æ¡

        # æ„å»ºè§’è‰²è®¾å®š
        characters_text = "\n".join([f"- {c['name']}: {c['personality']}" for c in characters])

        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªå‰§æœ¬åˆ›ä½œåŠ©æ‰‹ã€‚åœºæ™¯æ˜¯ï¼š{scene}

è§’è‰²è®¾å®šï¼š
{characters_text}

å¯¹è¯å†å²ï¼š
{history_text}

ç”¨æˆ·ï¼ˆçœŸå®ç©å®¶ï¼‰ï¼š{user_message}

è¯·è®©3ä¸ªè§’è‰²åˆ†åˆ«å¯¹ç”¨æˆ·çš„å‘è¨€åšå‡ºå›åº”ï¼Œç¬¦åˆå„è‡ªçš„æ€§æ ¼ã€‚
æ ¼å¼ï¼šè§’è‰²åï¼šå¯¹è¯å†…å®¹ï¼ˆæ¯è¡Œä¸€å¥ï¼‰
"""

        response = client.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt
        )

        messages = []
        for line in response.text.strip().split('\n'):
            if 'ï¼š' in line or ':' in line:
                sep = 'ï¼š' if 'ï¼š' in line else ':'
                speaker, content = line.split(sep, 1)
                messages.append({
                    'speaker': speaker.strip(),
                    'content': content.strip(),
                    'type': 'character'
                })

        return messages if messages else mock_generate_group_reply(scene, characters, chat_history, user_message)

    except Exception as e:
        st.warning(f"API è°ƒç”¨å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨ Mock æ•°æ®")
        return mock_generate_group_reply(scene, characters, chat_history, user_message)


def generate_private_reply_with_gemini(scene: str, character: Dict[str, str],
                                       chat_history: List[Dict[str, str]], user_message: str, api_key: str) -> str:
    """ä½¿ç”¨ Gemini API ç”Ÿæˆç§èŠå›å¤"""
    try:
        import google.genai as genai

        client = genai.Client(api_key=api_key)

        history_text = "\n".join([f"{msg['speaker']}ï¼š{msg['content']}" for msg in chat_history[-10:]])

        prompt = f"""
ä½ æ­£åœ¨æ‰®æ¼”è§’è‰²ï¼š{character['name']}ï¼ˆæ€§æ ¼ï¼š{character['personality']}ï¼‰
åœºæ™¯ï¼š{scene}

å¯¹è¯å†å²ï¼š
{history_text}

ç”¨æˆ·ï¼š{user_message}

è¯·ä»¥{character['name']}çš„èº«ä»½å’Œæ€§æ ¼å›å¤ç”¨æˆ·ï¼Œè¿™æ˜¯ç§èŠå¯¹è¯ã€‚
åªè¾“å‡ºå¯¹è¯å†…å®¹ï¼Œä¸è¦åŠ è§’è‰²åã€‚
"""

        response = client.models.generate_content(
            model='gemini-2.0-flash-exp',
            contents=prompt
        )

        return response.text.strip()

    except Exception as e:
        st.warning(f"API è°ƒç”¨å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨ Mock æ•°æ®")
        return mock_generate_private_reply(scene, character, chat_history, user_message)


def render_chat_message(msg: Dict[str, str]):
    """æ¸²æŸ“å•æ¡èŠå¤©æ¶ˆæ¯"""
    if msg['type'] == 'user':
        with st.chat_message("user", avatar="ğŸ§‘"):
            st.write(msg['content'])
    else:
        with st.chat_message("assistant", avatar="ğŸ­"):
            st.write(f"**{msg['speaker']}**: {msg['content']}")


def main():
    st.set_page_config(page_title="ç¾¤èŠå¯¹è¯ç”Ÿæˆå™¨", page_icon="ğŸ’¬", layout="wide")

    # åˆå§‹åŒ–
    init_session_state()

    st.title("ğŸ’¬ ç¾¤èŠå¯¹è¯ç”Ÿæˆå™¨")

    # ä¾§è¾¹æ ï¼šè®¾ç½®å’Œæ¨¡å¼åˆ‡æ¢
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")

        # é¢„è®¾å¯¼å…¥
        if not st.session_state.conversation_started:
            st.header("ğŸ“‚ å¿«é€Ÿå¼€å§‹")
            preset_file = st.file_uploader(
                "å¯¼å…¥é¢„è®¾",
                type=['json'],
                help="ä¸Šä¼ é¢„è®¾æ–‡ä»¶å¿«é€Ÿåˆå§‹åŒ–åœºæ™¯å’Œè§’è‰²"
            )

            if preset_file is not None:
                try:
                    json_str = preset_file.read().decode('utf-8')
                    if load_preset_from_json(json_str):
                        st.rerun()
                except Exception as e:
                    st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

            st.markdown("---")

        # API é…ç½®
        use_real_api = st.checkbox("ä½¿ç”¨çœŸå® Gemini API", value=False)
        if use_real_api:
            api_key = st.text_input("Gemini API Key",
                                   value=st.session_state.get('api_key', ''),
                                   type="password",
                                   help="ä» Google AI Studio è·å–")

            # v3.0.0: CrewAI å¼€å…³
            if CREWAI_AVAILABLE:
                use_crewai = st.checkbox(
                    "ğŸ¤– å¯ç”¨ CrewAI å¤š Agent ç³»ç»Ÿ",
                    value=True,
                    help="ä½¿ç”¨ CrewAI æ¡†æ¶å®ç°çœŸæ­£çš„å¤šæ™ºèƒ½ä½“åä½œï¼ˆæ¨èï¼‰"
                )
                st.session_state.use_crewai = use_crewai

                if use_crewai:
                    st.success("âœ… çœŸæ­£å¤š Agent æ¨¡å¼")
                else:
                    st.info("â„¹ï¸ ä¼ ç»Ÿé¡ºåºå‘è¨€æ¨¡å¼")
            else:
                st.warning("âš ï¸ CrewAI æœªå®‰è£…ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼")
        else:
            api_key = ""
            st.info("å½“å‰ä½¿ç”¨ Mock æ•°æ®æ¨¡å¼")

        st.markdown("---")

        # æ¨¡å¼åˆ‡æ¢
        st.header("ğŸ’¬ å¯¹è¯æ¨¡å¼")
        chat_mode = st.radio(
            "é€‰æ‹©æ¨¡å¼",
            options=['group', 'private'],
            format_func=lambda x: "ç¾¤èŠæ¨¡å¼" if x == 'group' else "ç§èŠæ¨¡å¼",
            key='mode_selector'
        )

        if chat_mode != st.session_state.chat_mode:
            st.session_state.chat_mode = chat_mode

        # ç§èŠæ¨¡å¼ä¸‹é€‰æ‹©è§’è‰²
        if st.session_state.chat_mode == 'private' and st.session_state.conversation_started:
            st.subheader("é€‰æ‹©ç§èŠå¯¹è±¡")
            character_names = [c['name'] for c in st.session_state.characters]
            selected = st.selectbox(
                "è§’è‰²",
                options=character_names,
                key='character_selector'
            )
            st.session_state.selected_character = selected

        st.markdown("---")

        # å…¨å±€è®°å¿†åŠŸèƒ½
        st.header("ğŸ’¾ å…¨å±€è®°å¿†")

        # ä¿å­˜å¯¹è¯
        if st.session_state.conversation_started:
            json_data = save_conversation_to_json()
            st.download_button(
                label="ğŸ’¾ ä¿å­˜å¯¹è¯",
                data=json_data,
                file_name=f"conversation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True,
                help="ä¿å­˜å½“å‰å¯¹è¯åˆ°æ–‡ä»¶ï¼ŒåŒ…æ‹¬åœºæ™¯ã€è§’è‰²å’Œæ‰€æœ‰å¯¹è¯å†å²"
            )
        else:
            st.info("å¼€å§‹å¯¹è¯åæ‰èƒ½ä¿å­˜")

        # åŠ è½½å¯¹è¯
        uploaded_file = st.file_uploader(
            "ğŸ“‚ åŠ è½½å¯¹è¯",
            type=['json'],
            help="ä¸Šä¼ ä¹‹å‰ä¿å­˜çš„å¯¹è¯æ–‡ä»¶"
        )

        if uploaded_file is not None:
            try:
                json_str = uploaded_file.read().decode('utf-8')
                if load_conversation_from_json(json_str):
                    st.success("âœ… å¯¹è¯åŠ è½½æˆåŠŸï¼")
                    st.rerun()
            except Exception as e:
                st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

        st.markdown("---")

        # é‡ç½®æŒ‰é’®
        if st.button("ğŸ”„ é‡æ–°å¼€å§‹", use_container_width=True):
            st.session_state.conversation_started = False
            st.session_state.shared_events = []
            st.session_state.character_memories = {}
            st.session_state.scene = ''
            st.session_state.characters = []
            st.rerun()

    # ä¸»ç•Œé¢
    if not st.session_state.conversation_started:
        # åˆå§‹è®¾ç½®ç•Œé¢
        st.header("ğŸ“ åœºæ™¯å’Œè§’è‰²è®¾ç½®")

        scene = st.text_area(
            "åœºæ™¯æè¿°",
            value=st.session_state.scene,
            placeholder="ä¾‹å¦‚ï¼šåœ¨ä¸€ä¸ªç¥ç§˜çš„å¤å ¡é‡Œï¼Œä¸‰ä¸ªå†’é™©å®¶æ­£åœ¨å¯»æ‰¾å®è—...",
            height=100
        )

        # è§’è‰²æ•°é‡æ§åˆ¶
        st.subheader("è§’è‰²è®¾ç½®")
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            st.markdown(f"**å½“å‰è§’è‰²æ•°é‡: {st.session_state.num_characters}** (èŒƒå›´: 2-8)")
        with col2:
            if st.button("â• æ·»åŠ è§’è‰²", disabled=st.session_state.num_characters >= 8):
                st.session_state.num_characters += 1
                st.rerun()
        with col3:
            if st.button("â– å‡å°‘è§’è‰²", disabled=st.session_state.num_characters <= 2):
                st.session_state.num_characters -= 1
                st.rerun()

        # åŠ¨æ€ç”Ÿæˆè§’è‰²è¾“å…¥æ¡†
        characters = []
        num_cols = min(st.session_state.num_characters, 4)  # æ¯è¡Œæœ€å¤š4ä¸ª
        rows = (st.session_state.num_characters + num_cols - 1) // num_cols

        for row in range(rows):
            cols = st.columns(num_cols)
            for col_idx in range(num_cols):
                char_idx = row * num_cols + col_idx + 1
                if char_idx <= st.session_state.num_characters:
                    with cols[col_idx]:
                        st.markdown(f"**è§’è‰² {char_idx}**")
                        name = st.text_input(
                            f"è§’è‰²{char_idx}åå­—",
                            key=f"setup_name_{char_idx}",
                            placeholder=f"è§’è‰²{char_idx}"
                        )
                        personality = st.text_area(
                            f"è§’è‰²{char_idx}æ€§æ ¼",
                            key=f"setup_personality_{char_idx}",
                            placeholder="ä¾‹å¦‚ï¼šå‹‡æ•¢ã€å†²åŠ¨ã€å–œæ¬¢å†’é™©...",
                            height=80
                        )
                        characters.append({"name": name, "personality": personality})

        st.markdown("---")

        if st.button("ğŸ­ å¼€å§‹å¯¹è¯", type="primary", use_container_width=True):
            # éªŒè¯è¾“å…¥
            if not scene.strip():
                st.error("è¯·è¾“å…¥åœºæ™¯æè¿°ï¼")
                return

            valid = True
            for i, char in enumerate(characters, 1):
                if not char['name'].strip():
                    st.error(f"è¯·è¾“å…¥è§’è‰²{i}çš„åå­—ï¼")
                    valid = False
                if not char['personality'].strip():
                    st.error(f"è¯·è¾“å…¥è§’è‰²{i}çš„æ€§æ ¼æè¿°ï¼")
                    valid = False

            if not valid:
                return

            # ä¿å­˜è®¾ç½®
            st.session_state.scene = scene
            st.session_state.characters = characters
            st.session_state.conversation_started = True

            # v2.2.0: åˆå§‹åŒ–æ–°çš„è®°å¿†ç³»ç»Ÿ
            st.session_state.shared_events = []
            init_character_memories()

            # v3.0.0: åˆå§‹åŒ– CrewAIï¼ˆå¦‚æœå¯ç”¨ä¸”æœ‰ API Keyï¼‰
            if CREWAI_AVAILABLE and st.session_state.use_crewai and api_key:
                try:
                    st.session_state.crew_manager = CharacterAgentCrew(
                        scene=scene,
                        characters=characters,
                        api_key=api_key
                    )
                except Exception as e:
                    st.error(f"CrewAI åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    st.session_state.crew_manager = None
            else:
                st.session_state.crew_manager = None

            st.rerun()

    else:
        # å¯¹è¯ç•Œé¢
        st.header(f"{'ğŸ‘¥ ç¾¤èŠ' if st.session_state.chat_mode == 'group' else 'ğŸ’¬ ç§èŠ'}")

        if st.session_state.chat_mode == 'group':
            # ç¾¤èŠæ¨¡å¼
            st.caption(f"åœºæ™¯ï¼š{st.session_state.scene}")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆåˆå§‹å¯¹è¯
            if len(st.session_state.shared_events) == 0:
                st.info("ğŸ’¬ è§’è‰²ä»¬æ­£åœ¨å¼€å§‹å¯¹è¯...")

                # é¡ºåºç”Ÿæˆåˆå§‹å¯¹è¯
                chat_placeholder = st.empty()
                status_placeholder = st.empty()

                for idx, char in enumerate(st.session_state.characters, 1):
                    status_placeholder.info(f"ğŸ¤” {char['name']} æ­£åœ¨æ€è€ƒ... ({idx}/{len(st.session_state.characters)})")

                    # è·å–è§’è‰²çš„å½“å‰è®°å¿†
                    char_memory = get_character_memory(char['name'])

                    # ç”Ÿæˆå‘è¨€
                    if use_real_api and api_key:
                        content = generate_single_reply_with_gemini(
                            st.session_state.scene,
                            char,
                            st.session_state.characters,
                            char_memory,
                            is_initial=True,
                            api_key=api_key
                        )
                    else:
                        content = mock_generate_single_reply(
                            st.session_state.scene,
                            char,
                            char_memory,
                            is_initial=True
                        )

                    # æ·»åŠ åˆ°è®°å¿†ç³»ç»Ÿ
                    add_group_message(char['name'], content, 'character')

                    # å®æ—¶æ˜¾ç¤ºæ›´æ–°åçš„å¯¹è¯
                    with chat_placeholder.container():
                        for msg in st.session_state.shared_events:
                            render_chat_message(msg)

                status_placeholder.success("âœ… åˆå§‹å¯¹è¯ç”Ÿæˆå®Œæˆï¼")
                st.rerun()

            # æ˜¾ç¤ºèŠå¤©å†å²
            chat_container = st.container()
            with chat_container:
                for msg in st.session_state.shared_events:
                    render_chat_message(msg)

            # ç”¨æˆ·äº¤äº’åŒºåŸŸ
            st.markdown("---")
            col1, col2 = st.columns([1, 1])

            with col1:
                user_input = st.chat_input("ğŸ’¬ è¾“å…¥ä½ çš„æ¶ˆæ¯ï¼Œå‚ä¸ç¾¤èŠ...")

            with col2:
                auto_continue_cols = st.columns([3, 1])
                with auto_continue_cols[0]:
                    num_rounds = st.number_input(
                        "è½®æ•°",
                        min_value=1,
                        max_value=5,
                        value=1,
                        key="auto_rounds",
                        help="è§’è‰²ä»¬è‡ªä¸»å¯¹è¯çš„è½®æ•°"
                    )
                with auto_continue_cols[1]:
                    auto_continue = st.button("ğŸ­ ç»§ç»­èŠ", use_container_width=True, help="è®©è§’è‰²ä»¬è‡ªä¸»ç»§ç»­å¯¹è¯")

            if user_input:
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°æ‰€æœ‰è§’è‰²çš„è®°å¿†
                add_group_message('ä½ ', user_input, 'user')

                status_placeholder = st.empty()

                # v3.0.0: ä½¿ç”¨ CrewAI æˆ–é™çº§æ¨¡å¼
                if st.session_state.crew_manager and CREWAI_AVAILABLE:
                    # CrewAI æ¨¡å¼ï¼šçœŸæ­£çš„å¤š Agent åä½œ
                    status_placeholder.info("ğŸ¤– å¤š Agent ç³»ç»Ÿæ­£åœ¨åä½œ...")

                    try:
                        # è¿è¡Œ CrewAI
                        responses = st.session_state.crew_manager.run_conversation_round(
                            user_message=user_input,
                            character_memories=st.session_state.character_memories
                        )

                        # å°†ç»“æœæ·»åŠ åˆ°è®°å¿†
                        for resp in responses:
                            if resp['content'] and resp['content'] != 'PASS':
                                add_group_message(resp['speaker'], resp['content'], 'character')

                    except Exception as e:
                        st.error(f"CrewAI æ‰§è¡Œé”™è¯¯: {str(e)}, é™çº§åˆ°ä¼ ç»Ÿæ¨¡å¼")
                        # é™çº§åˆ°ä¼ ç»Ÿæ¨¡å¼
                        _fallback_sequential_generation(user_input, use_real_api, api_key, status_placeholder)
                else:
                    # ä¼ ç»Ÿæ¨¡å¼ï¼šé¡ºåºå‘è¨€
                    _fallback_sequential_generation(user_input, use_real_api, api_key, status_placeholder)

                status_placeholder.empty()
                st.rerun()

            # è‡ªä¸»å¯¹è¯åŠŸèƒ½
            if auto_continue:
                status_placeholder = st.empty()

                for round_num in range(int(num_rounds)):
                    status_placeholder.info(f"ğŸ­ ç¬¬ {round_num + 1}/{int(num_rounds)} è½®è‡ªä¸»å¯¹è¯...")

                    # v3.0.0: ä½¿ç”¨ CrewAI æˆ–é™çº§æ¨¡å¼
                    if st.session_state.crew_manager and CREWAI_AVAILABLE:
                        # CrewAI æ¨¡å¼ï¼šè®© Agent è‡ªä¸»å†³å®šæ˜¯å¦å‘è¨€
                        try:
                            responses = st.session_state.crew_manager.run_conversation_round(
                                user_message=None,  # è‡ªä¸»å¯¹è¯ï¼Œæ— ç”¨æˆ·è¾“å…¥
                                character_memories=st.session_state.character_memories
                            )

                            # å°†ç»“æœæ·»åŠ åˆ°è®°å¿†
                            for resp in responses:
                                if resp['content'] and resp['content'] != 'PASS':
                                    add_group_message(resp['speaker'], resp['content'], 'character')

                        except Exception as e:
                            st.error(f"CrewAI æ‰§è¡Œé”™è¯¯: {str(e)}")
                            # é™çº§
                            _fallback_sequential_generation(None, use_real_api, api_key, status_placeholder)
                    else:
                        # ä¼ ç»Ÿæ¨¡å¼
                        _fallback_sequential_generation(None, use_real_api, api_key, status_placeholder)

                status_placeholder.success(f"âœ… å®Œæˆ {int(num_rounds)} è½®è‡ªä¸»å¯¹è¯ï¼")
                st.rerun()

        else:
            # ç§èŠæ¨¡å¼
            if not st.session_state.selected_character:
                st.info("è¯·åœ¨å·¦ä¾§é€‰æ‹©ä¸€ä¸ªè§’è‰²è¿›è¡Œç§èŠ")
                return

            selected_char_name = st.session_state.selected_character
            selected_char = next((c for c in st.session_state.characters if c['name'] == selected_char_name), None)

            if not selected_char:
                st.error("æœªæ‰¾åˆ°é€‰ä¸­çš„è§’è‰²")
                return

            st.caption(f"ä¸ {selected_char_name} ç§èŠ | åœºæ™¯ï¼š{st.session_state.scene}")

            # è·å–è¯¥è§’è‰²çš„ç§èŠæ¶ˆæ¯
            private_messages = get_private_messages(selected_char_name)

            # æ˜¾ç¤ºç§èŠå†å²
            chat_container = st.container()
            with chat_container:
                for msg in private_messages:
                    render_chat_message(msg)

            # ç”¨æˆ·è¾“å…¥
            user_input = st.chat_input(f"ä¸ {selected_char_name} ç§èŠ...")

            if user_input:
                # æ·»åŠ ç”¨æˆ·ç§èŠæ¶ˆæ¯
                add_private_message(selected_char_name, 'ä½ ', user_input, 'user')

                # ç”Ÿæˆè§’è‰²å›å¤ï¼ˆåŸºäºè§’è‰²çš„å®Œæ•´è®°å¿†ï¼‰
                with st.spinner(f"{selected_char_name} æ­£åœ¨å›å¤..."):
                    # è·å–è§’è‰²çš„å®Œæ•´è®°å¿†ï¼ˆç¾¤èŠ+ç§èŠï¼‰
                    char_memory = get_character_memory(selected_char_name)

                    if use_real_api and api_key:
                        reply_content = generate_single_reply_with_gemini(
                            st.session_state.scene,
                            selected_char,
                            st.session_state.characters,
                            char_memory,
                            is_initial=False,
                            api_key=api_key
                        )
                    else:
                        reply_content = mock_generate_single_reply(
                            st.session_state.scene,
                            selected_char,
                            char_memory,
                            is_initial=False
                        )

                    # æ·»åŠ è§’è‰²çš„ç§èŠå›å¤
                    add_private_message(selected_char_name, selected_char_name, reply_content, 'character')

                st.rerun()

        # å¯¼å‡ºå¯¹è¯æŒ‰é’®
        st.markdown("---")
        col1, col2 = st.columns([1, 1])

        with col1:
            if st.session_state.chat_mode == 'group':
                export_text = "\n".join([
                    f"{msg['speaker']}ï¼š{msg['content']}"
                    for msg in st.session_state.shared_events
                ])
                st.download_button(
                    label="ğŸ“¥ å¯¼å‡ºç¾¤èŠè®°å½•",
                    data=export_text,
                    file_name="group_chat.txt",
                    mime="text/plain"
                )

        with col2:
            if st.session_state.chat_mode == 'private' and st.session_state.selected_character:
                char_name = st.session_state.selected_character
                private_msgs = get_private_messages(char_name)
                export_text = "\n".join([
                    f"{msg['speaker']}ï¼š{msg['content']}"
                    for msg in private_msgs
                ])
                st.download_button(
                    label=f"ğŸ“¥ å¯¼å‡ºä¸{char_name}çš„ç§èŠ",
                    data=export_text,
                    file_name=f"private_chat_{char_name}.txt",
                    mime="text/plain"
                )


if __name__ == "__main__":
    main()
